# Guide Part 3: OpenMediaVault (OMV) Installation and Configuration

This guide covers setting up a virtual machine for OpenMediaVault (OMV) in Proxmox, configuring storage with SnapRAID and MergerFS, and setting up network shares.

---

## 1. Create the OpenMediaVault (NAS) VM

We'll use OpenMediaVault (OMV) because it's a lightweight, yet powerful, NAS operating system with an easy-to-use web interface.

1.  **Download OMV:** Download the [OpenMediaVault ISO](https://www.openmediavault.org/download.html).

2.  **Create the VM in Proxmox:**
    *   In the Proxmox UI, click **"Create VM"**.
    *   **General:** Name it something descriptive, like `OMV-NAS`. Note the **VM ID** (e.g., 100), as you'll need it later.
    *   **OS:** Upload and select the OMV ISO you just downloaded.
    *   **Hard Disk:** Create a small virtual disk (32GB is fine) on `local-lvm`. This is the fast NVMe storage where the OMV operating system will be installed.
    *   **CPU:** Assign 2 cores.
    *   **Memory:** Assign 2048 MB (2GB). OMV is very efficient.
    *   Confirm and finish. Start the VM and install OMV by following the on-screen prompts in the "Console" tab.

3.  **Pass Through Storage Drives:**
    *   **What is Drive Passthrough?** We want the OMV virtual machine to have direct, exclusive control over the physical hard drives for maximum reliability and performance. This is called "passing through" the drives.
    *   First, identify your drives. In the Proxmox server's shell (select the server name and open the "Shell"), type `ls -l /dev/disk/by-id/`. This lists all drives with stable, unique names.
    *   Use the `qm set` command to attach each physical drive to the OMV VM. Replace `<VM_ID>` with your OMV machine's ID and the disk name with the names you found.
        ```shell
        # Example for a VM with ID 100
        qm set 100 -scsi1 /dev/disk/by-id/<Disk_name>
        qm set 100 -scsi2 /dev/disk/by-id/<Disk_name>
        ```

## 2. Configure OMV Storage

*   Access the OMV web interface (find its IP in your router's device list).
*   **Wipe and Format:** Go to **Storage -> Drives**, and `Wipe` each of the newly attached drives. Then, in **File Systems**, `Create` and `Mount` a filesystem (like EXT4) on each one.

### Installing and Configuring SnapRAID and MergerFS

Now we'll install and configure the `openmediavault-snapraid` and `openmediavault-unionfilesystems` (for MergerFS) plugins.

1.  **Install OMV-Extras (if not already done):**
    *   These plugins require OMV-Extras. If you haven't installed it yet, connect to your OMV server via SSH and run:
        ```bash
        wget -O - https://github.com/OpenMediaVault-Plugin-Developers/packages/raw/master/install | bash
        ```
    *   Refresh your OMV web UI after the script completes.

2.  **Install the Plugins:**
    *   Navigate to **System > Plugins**.
    *   Search for and install `openmediavault-snapraid`.
    *   Search for and install `openmediavault-unionfilesystems`.
    > **<img width="1588" height="757" alt="image" src="https://github.com/user-attachments/assets/5f5868c5-09ae-4126-9c22-7679830f8106" />
**
    > *Caption: Installing the required plugins from the OMV Plugins page.*

3.  **Configure SnapRAID:**
    *   Go to **Services > SnapRAID**.
    *   **Create the Array:** In the `Settings` tab, click `Add` in the `Arrays` section to create a new array. You will configure your drives within this array definition.
      
    > **<img width="626" height="336" alt="image" src="https://github.com/user-attachments/assets/a87ae2d0-9ce5-4aaa-a5c3-ae0d93fd3a18" />
**
    > *Caption: Creating a new SnapRAID array.*
    *   **Add Drives to the Array:**
        *   In the `Drives` section of the `Add array` window, click `Add`.
        *   Select a drive from the dropdown, give it a name (e.g., `data1`), set the `Type` to `Data`, and click `OK`. Repeat this for all your data drives.
          
        > **<img width="929" height="397" alt="image" src="https://github.com/user-attachments/assets/a3c38755-9013-46d2-9910-637c2e2468e2" />
**
        > *Caption: Adding a data drive to the SnapRAID array definition.*
        
        *   Click `Add` again. Select your parity drive (it must be as large or larger than your biggest data drive), name it (e.g., `parity1`), set the `Type` to `Parity`, and click `OK`.
          
        > **<img width="798" height="501" alt="image" src="https://github.com/user-attachments/assets/386dcf43-a71c-4c1c-b265-b74456a88ee4" />
**
        > *Caption: Adding a parity drive to the SnapRAID array definition.*
        
    *   Once all drives are added to the array definition, click `Save`.
    *   **Run Initial Sync:** After saving the array, go to the `Tools` tab. Select your newly created array from the dropdown and click the `Start` button next to `Sync`. This builds the initial parity information and can take a long time.
    *   **Schedule Jobs:** Now, we'll set up automated tasks for SnapRAID.
        *   In the main OMV menu, go to **System > Scheduled Jobs**.
                        *   Click the `Add` button to create a new scheduled task.
          
          > **<img width="743" height="382" alt="image" src="https://github.com/user-attachments/assets/bc3a3d3d-9f0f-4710-a55f-537795f480df" />
**
          > *Caption: Adding a new scheduled task in OpenMediaVault.*

      *   **Create `snapraid sync` task (e.g., Daily):**            *   **Description:** `SnapRAID Sync Daily`
            *   **User:** `root`
            *   **Command:** `snapraid sync`
            *   **Schedule:** Choose an appropriate daily schedule (e.g., `Every day at 3:00 AM`).
            *   Click `Save`.
          >  **<img width="1088" height="838" alt="image" src="https://github.com/user-attachments/assets/55732d3e-85a1-427e-aa95-c3123d927297" />
**
          > *Caption: Configuration for the daily snapraid sync task.*
          
                        *   **Create `snapraid scrub` task (e.g., Weekly):**            *   **Description:** `SnapRAID Scrub Weekly`
            *   **User:** `root`
            *   **Command:** `snapraid scrub -p new -o 7` (This scrubs new data, and 7% of old data each week to ensure data integrity over time.)
            *   **Schedule:** Choose an appropriate weekly schedule (e.g., `Every Sunday at 4:00 AM`).
            *   Click `Save`.
          >  **<img width="1049" height="634" alt="image" src="https://github.com/user-attachments/assets/0b573c37-32bc-4de2-bf15-43a6a811bf59" />
**
          > *Caption: Configuration for the weekly snapraid scrub task.*
            
            *   After adding both tasks, click the `Apply` button in the top bar if prompted, to save the changes.

4.  **Configure MergerFS to Pool Your Drives:**
    *   Go to **Storage > Union Filesystems**.
    *   Click `Add` to create a new pool.
    *   **Name:** Give the pool a descriptive name, like `StoragePool`.
    *   **Branches:** Select ALL of your **data drives**. Do NOT include the parity drive in the pool.
      
    > **<img width="1553" height="538" alt="image" src="https://github.com/user-attachments/assets/e3b16656-9aff-49a6-aa56-c2c03688f9f7" />
**
    > *Caption: Selecting the data drives to include in the MergerFS pool.*
    
    *   **Create policy:** Select `Existing path, most free space`. This is a good general-purpose policy that tries to keep files for the same TV show or collection on the same drive while balancing free space.
    *   Save the new pool. It will now appear as a single large filesystem.
      
    > **<img width="439" height="85" alt="image" src="https://github.com/user-attachments/assets/59f28652-ca4b-4185-94dc-c35faa10f89c" />
**
    > *Caption: The newly created MergerFS pool is now visible in Union Filesystems.*

## 3. Create and Share the Media Folder via NFS

Now we will create a logical "Shared Folder" that points to our storage pool, and then share it over the network using NFS (Network File System). NFS is recommended over SMB/CIFS for this use case as it is more performant and efficient for Linux-based clients like our Jellyfin VM.

1.  **Create a Shared Folder:**
    *   Go to **Storage > Shared Folders** and click `Add`.
    *   **Name:** Give the folder a descriptive name, like `Media`.
    *   **File system:** From the dropdown, select your MergerFS pool (e.g., `StoragePool`).
    *   **Permissions:** This sets the underlying Linux permissions. A good starting point is `Administrator: read/write`, `Users: read/write`, `Others: read-only`.
    *   Save the shared folder.
    > **<img width="675" height="470" alt="image" src="https://github.com/user-attachments/assets/eccd3c12-b92c-40ef-837d-322ad841cc3f"**
    > *Caption: Creating a Shared Folder on the MergerFS pool.*

2.  **Enable and Configure the NFS Service:**
    *   Navigate to **Services > NFS > Settings**.
    *   Check the **"Enable"** box to turn on the NFS service.
    *   Click **"Save"** and then **"Apply"** the changes when prompted.
    > **<img width="339" height="247" alt="image" src="https://github.com/user-attachments/assets/02c44b7f-a8d0-439c-ac70-8564a3906339" />
**
    > *Caption: Enabling the global NFS service.*

3.  **Create the NFS Share:**
    *   Navigate to **Services > NFS > Shares** and click the **"Add"** button.
    *   In the "Add Share" window:
        *   **Shared Folder:** Select the `Media` shared folder you just created from the dropdown.
        *   **Client:** In the "Allowed clients" field, enter the IP address of your Jellyfin Ubuntu VM (e.g., `<Your IP>`). You can also use a subnet (e.g., `<Your IP>/24`) to allow access from any device on your local network.
        *   **Options:** For the simplest and most compatible setup, enter `rw,subtree_check`.
        *   `rw`: Stands for "read/write", giving the client permission to both read and write to the share.
            *   `subtree_check`: This is a security feature, and it's generally safe to leave it enabled.
        *   Save the new NFS share.
    > **<img width="1297" height="282" alt="image" src="https://github.com/user-attachments/assets/a6c508b6-364f-4adf-a990-bc88b35602ac" />
**
    > *Caption: Configuring the NFS share to make it available on the network.*

4.  **Apply Changes and Find Path:**
    *   A banner will appear at the top of the page. Click **"Apply"** to activate the new NFS share.
    *   After applying, the "Exported path" column in the shares list will show the full path for your share (e.g., `/export/Media`). **Make a note of this exact path**, as you will need it to configure the client VM.

Your `Media` share is now active on the network via NFS. Unlike SMB, you do not need to create a separate `mediauser` for this setup, as NFS handles access based on IP address.
